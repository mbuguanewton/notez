{
  "notes": [
    {
      "id": "ad90748d-724e-401b-b1c7-b256502c772c",
      "title": "Notes: Kenya - Wikipedia",
      "content": "<h1>Kenya - Wikipedia</h1><p><strong>URL:</strong> <a href=\"https://en.wikipedia.org/wiki/Kenya\">https://en.wikipedia.org/wiki/Kenya</a></p><p></p><p>Add your notes here...</p>",
      "createdAt": "2025-07-31T17:15:12.861Z",
      "updatedAt": "2025-07-31T17:15:12.865Z",
      "tags": [
        "web-page",
        "en.wikipedia.org"
      ],
      "source": {
        "url": "https://en.wikipedia.org/wiki/Kenya",
        "title": "Kenya - Wikipedia",
        "domain": "en.wikipedia.org",
        "capturedAt": "2025-07-31T17:15:01.809Z"
      }
    },
    {
      "title": "Notes: LLM Intelligent Customer Service in Property Management Using a RAG Approach | IEEE Conference Publication | IEEE Xplore",
      "content": "<h1>LLM Intelligent Customer Service in Property Management Using a RAG Approach | IEEE Conference Publication | IEEE Xplore</h1><p><strong>URL:</strong> <a href=\"https://ieeexplore.ieee.org/abstract/document/10900207\">https://ieeexplore.ieee.org/abstract/document/10900207</a></p><p></p><p>Add your notes here...</p>\n<hr>\n<h3>üìù Added Notes (01/08/2025, 11:33:08)</h3>\n<p>Traditional property management services often struggle with challenges such as long response times and difficulties in effectively addressing complex tenant issues. While Large Language Models (LLMs), like ChatGPT, offer promising solutions, they are often limited by their lack of domain-specific knowledge, leading to inaccurate or irrelevant responses. To address these shortcomings, this paper introduces an intelligent customer service system tailored for property management. The system integrates a customized LLM with the Retrieval Augmented Generation (RAG) framework, designed to provide accurate, context-aware, and personalized responses.</p>\n\n<hr>\n<h3>üìù Added Notes (01/08/2025, 14:05:44)</h3>\n<p>Traditional property management services often struggle with challenges such as long response times and difficulties in effectively addressing complex tenant issues. While Large Language Models (LLMs), like ChatGPT, offer promising solutions, they are often limited by their lack of domain-specific knowledge, leading to inaccurate or irrelevant responses. To address these shortcomings, this paper introduces an intelligent customer service system tailored for property management. The system integrates a customized LLM with the Retrieval Augmented Generation (RAG) framework, designed to provide accurate, context-aware, and personalized responses. By employing an intelligent agent to pull relevant data from a dedicated property management knowledge base, the system can engage tenants in real-time through an interactive interface, ensuring both efficiency and relevance in communication. Additionally, machine learning algorithms are employed to continuously improve the system‚Äôs performance.</p>\n\n<hr>\n<h3>üìù Selected Text (01/08/2025, 16:19:53)</h3>\n<blockquote>\"re often limited by their lack of domain-specific knowledge, leading to inaccurate or irrelevant responses. To address these sh\"</blockquote>\n<p><em>Add your notes about this selection...</em></p>\n\n<hr>\n<h3>üìù Selected Text (01/08/2025, 16:20:17)</h3>\n<blockquote>\"This study contributes to the broader fields of Artificial Intelligence, Robotics, and Communication by showcasing how RAG can be applied to improve customer service, with future work\"</blockquote>\n<p><em>Add your notes about this selection...</em></p>\n\n<hr>\n<h3>üìù Selected Text (01/08/2025, 16:30:57)</h3>\n<blockquote>\". Additionally, machine learning algorithms are employed to continuously imp\"</blockquote>\n<p><em>Add your notes about this selection...</em></p>\n",
      "updatedAt": "2025-08-01T17:00:20.801Z",
      "id": "40a67144-d6da-4bc7-97c6-871ce6ff3974"
    },
    {
      "title": "Notes: Egyptian pyramids - Wikipedia",
      "content": "<h1>Egyptian pyramids - Wikipedia</h1><p><strong>URL:</strong> <a href=\"https://en.wikipedia.org/wiki/Egyptian_pyramids\">https://en.wikipedia.org/wiki/Egyptian_pyramids</a></p><p></p><p>Add your notes here...</p>\n<hr>\n<h3>üìù Selected Text (03/08/2025, 17:31:01)</h3>\n<blockquote>\"The shape of Egyptian pyramids is thought to represent the primordial mound from which the Egyptians believed the earth was created. The shape of a pyramid is also thought to be representative of the descending rays of the sun, and most pyramids w\"</blockquote>\n<p><em>Add your notes about this selection...</em></p>\n",
      "updatedAt": "2025-08-03T16:48:58.522Z",
      "id": "mdsqbkusqd198tnd9wr"
    },
    {
      "id": "mdt02btealsb0qsl0x",
      "title": "Notes: Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection | IEEE Conference Publication | IEEE Xplore",
      "content": "<h1>Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection | IEEE Conference Publication | IEEE Xplore</h1><p><strong>URL:</strong> <a href=\"https://ieeexplore.ieee.org/abstract/document/10651296\">https://ieeexplore.ieee.org/abstract/document/10651296</a></p><p></p><p>Add your notes here...</p>\n<hr>\n<h3>üìù Selected Text (04/08/2025, 14:10:55)</h3>\n<blockquote>\"The results indicate the effectiveness, good generalization ability, and great potential of adaptive ensemble algorithms in LLM-generated text detection.\"</blockquote>\n<p><em>Add your notes about this selection...</em></p>\n\n<hr>\n<h3>üìù Selected Text (04/08/2025, 14:12:16)</h3>\n<blockquote>\"Previous research has mostly tested single models on in-distribution datasets, limiting our understanding of how these models perform on different types of data for LLM-generated text detection tasks. We researched this by testing five specialized transformer-based models on both in-distribution and out-of-distribution datasets to better assess their performance and generalizability. Our results revealed that single transformer-based classifiers achieved decent performance on the in-distribution dataset but limited generalization ability on the out-of-distribution dataset. To improve it, we combined the individual classifier models using adaptive ensemble algorithms, which improved the average accuracy significantly from 91.8% to 99.2% on an in-distribution test set and from 62.9% to 72.5% on an out-of-distribution test set. The results indicate the effectiveness, good generalization ability, and great potential of adaptive ensemble algorithms in LLM-generated text detection.\nPublished in: 2024 International Joint Conference on Neural Networks (IJCNN)\nDate of Conference: 30 June 2024 - 05 July 2024\nDate Added to IEEE Xplore: 09 September 2024\nISBN Information:\nISSN Information:\nDOI: 10.1109/IJCNN60899.2024.10651296\nPublisher: IEEE\nConference Location: Yokohama, Japan\nI. Introduction\nRecently, LLM has experienced rapid development, and its text generation ability is comparable to that of human writing [1]. LLM has penetrated various aspects of daily life and plays a crucial role in many professional workflows such as forecasting and anomaly detection [2], text production [3], reasoning [4], naming [5], promoting tasks [6], vision [7], and across various domains [8]‚Äì[13]. In addition, their impact has significantly influenced the development of many sectors and disciplines, including education [14], law [15], biology [16], and medicine [17], agriculture [18]. However, the use of GPTs also brings various risks.\n\nSign in to Continue Reading\n\nAuthors\n\nFigures\n\nReferences\n\nCitations\n\nKeywords\n\nMetrics\n\nFootnotes\n\nMore Like This\nResearch on the Construction of Knowledge QA System Driven by Large Language Model: One Case Study of Power Transformer Domain\n2024 7th International Conference on Data Science and Information Technology (DSIT)\n\nPublished: 2024\n\nComparative Analysis of Transformer-based Large Language Models (LLMs) for Text Summarization\n2024 1st International Conference on Advanced Computing and Emerging Technologies (ACET)\n\nPublished: 2024\n\nShow More\nReferences\n\nReferences is not available for this document.\nIEEE Personal Account\nCHANGE USERNAME/PASSWORD\nPurchase Details\nPAYMENT OPTIONS\nVIEW PURCHASED DOCUMENTS\nProfile Information\nCOMMUNICATIONS PREFERENCES\nPROFESSION AND EDUCATION\nTECHNICAL INTERESTS\nNeed Help?\nUS &amp; CANADA: +1 800 678 4333\nWORLDWIDE: +1 732 981 0060\nCONTACT &amp; SUPPORT\nFollow\nAbout IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy\n\nA public charity, IEEE is the world&#039;s largest technical professional organization dedicated to advancing technology for the benefit of humanity.\n\n¬© Copyright 2025 IEEE - All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies.\n\n\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\nüìù Add to Page Note\"</blockquote>\n<p><em>Add your notes about this selection...</em></p>\n",
      "tags": [
        "web-page",
        "ieeexplore.ieee.org"
      ],
      "source": {
        "url": "https://ieeexplore.ieee.org/abstract/document/10651296",
        "title": "Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection | IEEE Conference Publication | IEEE Xplore",
        "domain": "ieeexplore.ieee.org",
        "capturedAt": "2025-08-01T15:49:55.087Z"
      },
      "updatedAt": "2025-08-04T13:12:16.850Z",
      "createdAt": "2025-08-01T15:50:08.210Z"
    },
    {
      "id": "mdt2q1fbnjvjbjhqmy",
      "title": "Notes: pdfs.semanticscholar.org/4029/9c8515c22705f8e42acddf0ade59c754f350.pdfhttp://creativecommons.org/licenses/by/4.0/",
      "content": "<h1>pdfs.semanticscholar.org/4029/9c8515c22705f8e42acddf0ade59c754f350.pdfhttp://creativecommons.org/licenses/by/4.0/</h1><p><strong>URL:</strong> <a href=\"https://pdfs.semanticscholar.org/4029/9c8515c22705f8e42acddf0ade59c754f350.pdfhttp://creativecommons.org/licenses/by/4.0/\">https://pdfs.semanticscholar.org/4029/9c8515c22705f8e42acddf0ade59c754f350.pdfhttp://creativecommons.org/licenses/by/4.0/</a></p><p></p><p>Add your notes here...</p>",
      "tags": [
        "web-page",
        "pdfs.semanticscholar.org"
      ],
      "source": {
        "url": "https://pdfs.semanticscholar.org/4029/9c8515c22705f8e42acddf0ade59c754f350.pdfhttp://creativecommons.org/licenses/by/4.0/",
        "title": "pdfs.semanticscholar.org/4029/9c8515c22705f8e42acddf0ade59c754f350.pdfhttp://creativecommons.org/licenses/by/4.0/",
        "domain": "pdfs.semanticscholar.org",
        "capturedAt": "2025-08-01T17:04:28.485Z"
      },
      "updatedAt": "2025-08-01T17:04:33.719Z",
      "createdAt": "2025-08-01T17:04:33.719Z"
    },
    {
      "id": "mdx4au0v0f5dfoy11ze7",
      "title": "Notes: Documentation | Apache Airflow",
      "content": "<h1>Documentation | Apache Airflow</h1><p><strong>URL:</strong> <a href=\"https://airflow.apache.org/docs/\">https://airflow.apache.org/docs/</a></p><p></p><p>Add your notes here...</p>\n<hr>\n<h3>üìù Selected Text (04/08/2025, 14:00:17)</h3>\n<blockquote>\"with Airflow resources (e.g., Connections, Variables, XComs, Metrics, Logs, and OpenLineage events) at runtime. The goal of task-sdk is to decouple DAG authoring from Airflow internals (Scheduler, API Server, etc.), providing a forward-compatible, stable interface for writing\"</blockquote>\n<p><em>Add your notes about this selection...</em></p>\n",
      "tags": [
        "web-page",
        "airflow.apache.org"
      ],
      "source": {
        "url": "https://airflow.apache.org/docs/",
        "title": "Documentation | Apache Airflow",
        "domain": "airflow.apache.org",
        "capturedAt": "2025-08-04T12:59:43.700Z"
      },
      "updatedAt": "2025-08-04T13:00:17.244Z",
      "createdAt": "2025-08-04T12:59:48.223Z"
    },
    {
      "id": "mdx4q1ijjgy5l7re2a",
      "title": "Selection from Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection | IEEE Conference Publication | IEEE Xplore",
      "content": "<blockquote>\"Large language models (LLMs) have reached human-like proficiency in generating diverse textual content, underscoring the necessity for effective fake text detection to avoid potential risks such as fake news in social media.\"</blockquote><p>From: <a href=\"https://ieeexplore.ieee.org/abstract/document/10651296\">Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection | IEEE Conference Publication | IEEE Xplore</a></p>",
      "tags": [
        "selection",
        "web"
      ],
      "source": {
        "url": "https://ieeexplore.ieee.org/abstract/document/10651296",
        "title": "Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection | IEEE Conference Publication | IEEE Xplore",
        "type": "selection"
      },
      "updatedAt": "2025-08-04T13:11:37.771Z",
      "createdAt": "2025-08-04T13:11:37.771Z"
    }
  ],
  "settings": {
    "theme": "light",
    "shortcuts": {
      "quickNote": "Alt+Shift+N",
      "toggleSidepanel": "Alt+Shift+S",
      "captureSelection": "Alt+Shift+Q"
    }
  }
}